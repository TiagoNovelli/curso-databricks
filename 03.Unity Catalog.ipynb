{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22a7d50f-a28b-4120-bb75-38f77e503925",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'/Volumes/infinitybd/default/teste/iot/' --caminho pasta\n",
    "'/Volumes/infinitybd/default/teste/iot/iot_devices.json' -- Caminho arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8651a3c9-57b7-4b85-9999-91f221f682e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "'/Volumes/infinitybd/default/teste/iot/'\n",
    "'/Volumes/infinitybd/default/teste/iot/iot_devices.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1541b1b8-0926-4934-94b1-4cddcd9e73af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/iot/iot_devices.json</td><td>iot_devices.json</td><td>62509052</td><td>1523820707000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/databricks-datasets/iot/iot_devices.json",
         "iot_devices.json",
         62509052,
         1523820707000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs\n",
    "ls 'dbfs:/databricks-datasets/iot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "633ea4ae-483e-49f9-92a0-30b827ca8f23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>battery_level</th><th>c02_level</th><th>cca2</th><th>cca3</th><th>cn</th><th>device_id</th><th>device_name</th><th>humidity</th><th>ip</th><th>latitude</th><th>lcd</th><th>longitude</th><th>scale</th><th>temp</th><th>timestamp</th></tr></thead><tbody><tr><td>8</td><td>868</td><td>US</td><td>USA</td><td>United States</td><td>1</td><td>meter-gauge-1xbYRYcj</td><td>51</td><td>68.161.225.1</td><td>38.0</td><td>green</td><td>-97.0</td><td>Celsius</td><td>34</td><td>1458444054093</td></tr><tr><td>7</td><td>1473</td><td>NO</td><td>NOR</td><td>Norway</td><td>2</td><td>sensor-pad-2n2Pea</td><td>70</td><td>213.161.254.1</td><td>62.47</td><td>red</td><td>6.15</td><td>Celsius</td><td>11</td><td>1458444054119</td></tr><tr><td>2</td><td>1556</td><td>IT</td><td>ITA</td><td>Italy</td><td>3</td><td>device-mac-36TWSKiT</td><td>44</td><td>88.36.5.1</td><td>42.83</td><td>red</td><td>12.83</td><td>Celsius</td><td>19</td><td>1458444054120</td></tr><tr><td>6</td><td>1080</td><td>US</td><td>USA</td><td>United States</td><td>4</td><td>sensor-pad-4mzWkz</td><td>32</td><td>66.39.173.154</td><td>44.06</td><td>yellow</td><td>-121.32</td><td>Celsius</td><td>28</td><td>1458444054121</td></tr><tr><td>4</td><td>931</td><td>PH</td><td>PHL</td><td>Philippines</td><td>5</td><td>therm-stick-5gimpUrBB</td><td>62</td><td>203.82.41.9</td><td>14.58</td><td>green</td><td>120.97</td><td>Celsius</td><td>25</td><td>1458444054122</td></tr><tr><td>3</td><td>1210</td><td>US</td><td>USA</td><td>United States</td><td>6</td><td>sensor-pad-6al7RTAobR</td><td>51</td><td>204.116.105.67</td><td>35.93</td><td>yellow</td><td>-85.46</td><td>Celsius</td><td>27</td><td>1458444054122</td></tr><tr><td>3</td><td>1129</td><td>CN</td><td>CHN</td><td>China</td><td>7</td><td>meter-gauge-7GeDoanM</td><td>26</td><td>220.173.179.1</td><td>22.82</td><td>yellow</td><td>108.32</td><td>Celsius</td><td>18</td><td>1458444054123</td></tr><tr><td>0</td><td>1536</td><td>JP</td><td>JPN</td><td>Japan</td><td>8</td><td>sensor-pad-8xUD6pzsQI</td><td>35</td><td>210.173.177.1</td><td>35.69</td><td>red</td><td>139.69</td><td>Celsius</td><td>27</td><td>1458444054123</td></tr><tr><td>3</td><td>807</td><td>JP</td><td>JPN</td><td>Japan</td><td>9</td><td>device-mac-9GcjZ2pw</td><td>85</td><td>118.23.68.227</td><td>35.69</td><td>green</td><td>139.69</td><td>Celsius</td><td>13</td><td>1458444054124</td></tr><tr><td>7</td><td>1470</td><td>US</td><td>USA</td><td>United States</td><td>10</td><td>sensor-pad-10BsywSYUF</td><td>56</td><td>208.109.163.218</td><td>33.61</td><td>red</td><td>-111.89</td><td>Celsius</td><td>26</td><td>1458444054125</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         8,
         868,
         "US",
         "USA",
         "United States",
         1,
         "meter-gauge-1xbYRYcj",
         51,
         "68.161.225.1",
         38.0,
         "green",
         -97.0,
         "Celsius",
         34,
         1458444054093
        ],
        [
         7,
         1473,
         "NO",
         "NOR",
         "Norway",
         2,
         "sensor-pad-2n2Pea",
         70,
         "213.161.254.1",
         62.47,
         "red",
         6.15,
         "Celsius",
         11,
         1458444054119
        ],
        [
         2,
         1556,
         "IT",
         "ITA",
         "Italy",
         3,
         "device-mac-36TWSKiT",
         44,
         "88.36.5.1",
         42.83,
         "red",
         12.83,
         "Celsius",
         19,
         1458444054120
        ],
        [
         6,
         1080,
         "US",
         "USA",
         "United States",
         4,
         "sensor-pad-4mzWkz",
         32,
         "66.39.173.154",
         44.06,
         "yellow",
         -121.32,
         "Celsius",
         28,
         1458444054121
        ],
        [
         4,
         931,
         "PH",
         "PHL",
         "Philippines",
         5,
         "therm-stick-5gimpUrBB",
         62,
         "203.82.41.9",
         14.58,
         "green",
         120.97,
         "Celsius",
         25,
         1458444054122
        ],
        [
         3,
         1210,
         "US",
         "USA",
         "United States",
         6,
         "sensor-pad-6al7RTAobR",
         51,
         "204.116.105.67",
         35.93,
         "yellow",
         -85.46,
         "Celsius",
         27,
         1458444054122
        ],
        [
         3,
         1129,
         "CN",
         "CHN",
         "China",
         7,
         "meter-gauge-7GeDoanM",
         26,
         "220.173.179.1",
         22.82,
         "yellow",
         108.32,
         "Celsius",
         18,
         1458444054123
        ],
        [
         0,
         1536,
         "JP",
         "JPN",
         "Japan",
         8,
         "sensor-pad-8xUD6pzsQI",
         35,
         "210.173.177.1",
         35.69,
         "red",
         139.69,
         "Celsius",
         27,
         1458444054123
        ],
        [
         3,
         807,
         "JP",
         "JPN",
         "Japan",
         9,
         "device-mac-9GcjZ2pw",
         85,
         "118.23.68.227",
         35.69,
         "green",
         139.69,
         "Celsius",
         13,
         1458444054124
        ],
        [
         7,
         1470,
         "US",
         "USA",
         "United States",
         10,
         "sensor-pad-10BsywSYUF",
         56,
         "208.109.163.218",
         33.61,
         "red",
         -111.89,
         "Celsius",
         26,
         1458444054125
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "battery_level",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "c02_level",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cca2",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cca3",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cn",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "device_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "device_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "humidity",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ip",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "latitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "lcd",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "longitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "scale",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "temp",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from json.`dbfs:/databricks-datasets/iot/iot_devices.json` limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1e344b3-b89f-4608-a4ed-6a0408d4efa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Copiar este arquivo para nosso DBFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31999830-eb34-4d6d-842c-16018430493b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%python\n",
    "\n",
    "'''dbutils.fs.cp(\n",
    "    'dbfs:/databricks-datasets/iot/iot_devices.json',\n",
    "    'dbfs:/mnt/iot/iot_devices.json'\n",
    ")\n",
    "'''\n",
    "#nova versao \n",
    "#criar volume no catalog - mnt (mesma coisa que pasta)\n",
    "dbutils.fs.cp(\n",
    "    'dbfs:/databricks-datasets/iot/iot_devices.json',\n",
    "    '/Volumes/infinitybd/default/mnt/iot/iot_devices.json'\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a490d46f-4198-473d-8656-bab4fa16eb14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volumes/infinitybd/default/mnt/iot/iot_devices.json</td><td>iot_devices.json</td><td>62509052</td><td>1755191189000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/infinitybd/default/mnt/iot/iot_devices.json",
         "iot_devices.json",
         62509052,
         1755191189000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "#display(dbutils.fs.ls('dbfs:/mnt/iot/')) #Antigo DBFS\n",
    "display(dbutils.fs.ls('/Volumes/infinitybd/default/mnt/iot/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c35e55bd-2536-4b50-a2a2-447f69d0cc2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>battery_level</th><th>c02_level</th><th>cca2</th><th>cca3</th><th>cn</th><th>device_id</th><th>device_name</th><th>humidity</th><th>ip</th><th>latitude</th><th>lcd</th><th>longitude</th><th>scale</th><th>temp</th><th>timestamp</th></tr></thead><tbody><tr><td>8</td><td>868</td><td>US</td><td>USA</td><td>United States</td><td>1</td><td>meter-gauge-1xbYRYcj</td><td>51</td><td>68.161.225.1</td><td>38.0</td><td>green</td><td>-97.0</td><td>Celsius</td><td>34</td><td>1458444054093</td></tr><tr><td>7</td><td>1473</td><td>NO</td><td>NOR</td><td>Norway</td><td>2</td><td>sensor-pad-2n2Pea</td><td>70</td><td>213.161.254.1</td><td>62.47</td><td>red</td><td>6.15</td><td>Celsius</td><td>11</td><td>1458444054119</td></tr><tr><td>2</td><td>1556</td><td>IT</td><td>ITA</td><td>Italy</td><td>3</td><td>device-mac-36TWSKiT</td><td>44</td><td>88.36.5.1</td><td>42.83</td><td>red</td><td>12.83</td><td>Celsius</td><td>19</td><td>1458444054120</td></tr><tr><td>6</td><td>1080</td><td>US</td><td>USA</td><td>United States</td><td>4</td><td>sensor-pad-4mzWkz</td><td>32</td><td>66.39.173.154</td><td>44.06</td><td>yellow</td><td>-121.32</td><td>Celsius</td><td>28</td><td>1458444054121</td></tr><tr><td>4</td><td>931</td><td>PH</td><td>PHL</td><td>Philippines</td><td>5</td><td>therm-stick-5gimpUrBB</td><td>62</td><td>203.82.41.9</td><td>14.58</td><td>green</td><td>120.97</td><td>Celsius</td><td>25</td><td>1458444054122</td></tr><tr><td>3</td><td>1210</td><td>US</td><td>USA</td><td>United States</td><td>6</td><td>sensor-pad-6al7RTAobR</td><td>51</td><td>204.116.105.67</td><td>35.93</td><td>yellow</td><td>-85.46</td><td>Celsius</td><td>27</td><td>1458444054122</td></tr><tr><td>3</td><td>1129</td><td>CN</td><td>CHN</td><td>China</td><td>7</td><td>meter-gauge-7GeDoanM</td><td>26</td><td>220.173.179.1</td><td>22.82</td><td>yellow</td><td>108.32</td><td>Celsius</td><td>18</td><td>1458444054123</td></tr><tr><td>0</td><td>1536</td><td>JP</td><td>JPN</td><td>Japan</td><td>8</td><td>sensor-pad-8xUD6pzsQI</td><td>35</td><td>210.173.177.1</td><td>35.69</td><td>red</td><td>139.69</td><td>Celsius</td><td>27</td><td>1458444054123</td></tr><tr><td>3</td><td>807</td><td>JP</td><td>JPN</td><td>Japan</td><td>9</td><td>device-mac-9GcjZ2pw</td><td>85</td><td>118.23.68.227</td><td>35.69</td><td>green</td><td>139.69</td><td>Celsius</td><td>13</td><td>1458444054124</td></tr><tr><td>7</td><td>1470</td><td>US</td><td>USA</td><td>United States</td><td>10</td><td>sensor-pad-10BsywSYUF</td><td>56</td><td>208.109.163.218</td><td>33.61</td><td>red</td><td>-111.89</td><td>Celsius</td><td>26</td><td>1458444054125</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         8,
         868,
         "US",
         "USA",
         "United States",
         1,
         "meter-gauge-1xbYRYcj",
         51,
         "68.161.225.1",
         38.0,
         "green",
         -97.0,
         "Celsius",
         34,
         1458444054093
        ],
        [
         7,
         1473,
         "NO",
         "NOR",
         "Norway",
         2,
         "sensor-pad-2n2Pea",
         70,
         "213.161.254.1",
         62.47,
         "red",
         6.15,
         "Celsius",
         11,
         1458444054119
        ],
        [
         2,
         1556,
         "IT",
         "ITA",
         "Italy",
         3,
         "device-mac-36TWSKiT",
         44,
         "88.36.5.1",
         42.83,
         "red",
         12.83,
         "Celsius",
         19,
         1458444054120
        ],
        [
         6,
         1080,
         "US",
         "USA",
         "United States",
         4,
         "sensor-pad-4mzWkz",
         32,
         "66.39.173.154",
         44.06,
         "yellow",
         -121.32,
         "Celsius",
         28,
         1458444054121
        ],
        [
         4,
         931,
         "PH",
         "PHL",
         "Philippines",
         5,
         "therm-stick-5gimpUrBB",
         62,
         "203.82.41.9",
         14.58,
         "green",
         120.97,
         "Celsius",
         25,
         1458444054122
        ],
        [
         3,
         1210,
         "US",
         "USA",
         "United States",
         6,
         "sensor-pad-6al7RTAobR",
         51,
         "204.116.105.67",
         35.93,
         "yellow",
         -85.46,
         "Celsius",
         27,
         1458444054122
        ],
        [
         3,
         1129,
         "CN",
         "CHN",
         "China",
         7,
         "meter-gauge-7GeDoanM",
         26,
         "220.173.179.1",
         22.82,
         "yellow",
         108.32,
         "Celsius",
         18,
         1458444054123
        ],
        [
         0,
         1536,
         "JP",
         "JPN",
         "Japan",
         8,
         "sensor-pad-8xUD6pzsQI",
         35,
         "210.173.177.1",
         35.69,
         "red",
         139.69,
         "Celsius",
         27,
         1458444054123
        ],
        [
         3,
         807,
         "JP",
         "JPN",
         "Japan",
         9,
         "device-mac-9GcjZ2pw",
         85,
         "118.23.68.227",
         35.69,
         "green",
         139.69,
         "Celsius",
         13,
         1458444054124
        ],
        [
         7,
         1470,
         "US",
         "USA",
         "United States",
         10,
         "sensor-pad-10BsywSYUF",
         56,
         "208.109.163.218",
         33.61,
         "red",
         -111.89,
         "Celsius",
         26,
         1458444054125
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "battery_level",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "c02_level",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cca2",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cca3",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cn",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "device_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "device_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "humidity",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ip",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "latitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "lcd",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "longitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "scale",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "temp",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- consulta em arquivo JSON\n",
    "select * from json.`/Volumes/infinitybd/default/mnt/iot/iot_devices.json` limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b627896-9b82-47a7-8bed-f8ced306e309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- consulta em arquivo JSON\n",
    "select * from json.`/Volumes/infinitybd/default/mnt/iot/*.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77495be6-bde5-4e2d-b79e-c6e817234357",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Transformando arquivo em tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e46896c9-6db9-4392-963e-896637dadbdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volumes/infinitybd/default/mnt/iot/</td><td>iot/</td><td>0</td><td>1755191186000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/infinitybd/default/mnt/iot/",
         "iot/",
         0,
         1755191186000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls('/Volumes/infinitybd/default/mnt/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "923fe441-6b4e-4e99-9417-959481410e10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volumes/infinitybd/default/mnt/iot/iot_devices.json</td><td>iot_devices.json</td><td>62509052</td><td>1755191189000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/infinitybd/default/mnt/iot/iot_devices.json",
         "iot_devices.json",
         62509052,
         1755191189000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls('/Volumes/infinitybd/default/mnt/iot/'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0a8c9dd-4627-4e02-abc5-7f25bcd00884",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Comando Using<br>\n",
    "DBFS é considerado storage gerenciado antigo, válido para Hive Metastore legado.\n",
    "\n",
    "Unity Catalog exige External Locations ou storage externo (ADLS Gen2, S3) para tabelas apontando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94f5ef67-18a2-43fd-ad81-2d976041c9fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- Lê o JSON e cria a temp view\n",
    "CREATE OR REPLACE TEMP VIEW iot_devices_temp\n",
    "USING json\n",
    "OPTIONS (\n",
    "  path 'dbfs:/Volumes/infinitybd/default/mnt/iot/'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bab7413-0fa3-44ea-9bdd-88e626f2e352",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Lê o JSON e cria a temp view\n",
    "CREATE OR REPLACE  TABLE infinitybd.default.iot_devicesj22\n",
    "USING json\n",
    "OPTIONS (\n",
    "  path 'dbfs:/Volumes/infinitybd/default/mnt/iot/'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87dd66fb-d39c-4c37-b621-1b58e0e6e696",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Cria uma tabela a partir do arquivo JSON com comando Using \n",
    "CREATE TABLE infinitybd.default.iot_devicesj\n",
    "USING json\n",
    "LOCATION 'dbfs:/Volumes/infinitybd/default/mnt/iot/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee04952e-fcd7-4195-878c-5e0841048c3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.sql.managedcatalog.UnityCatalogServiceException: [RequestId=1391a6f6-5844-4086-aa36-c4cad6d95014 ErrorClass=INVALID_PARAMETER_VALUE.INVALID_PARAMETER_VALUE] Missing cloud file system scheme\n",
       "\tat com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:118)\n",
       "\tat com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:63)\n",
       "\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:251)\n",
       "\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7378)\n",
       "\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7364)\n",
       "\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.generateTemporaryPathCredentials(ManagedCatalogClientImpl.scala:6421)\n",
       "\tat com.databricks.sql.managedcatalog.ManagedCatalogCommon.generateTemporaryPathCredentials(ManagedCatalogCommon.scala:3238)\n",
       "\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$generateTemporaryPathCredentials$2(ProfiledManagedCatalog.scala:726)\n",
       "\tat org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:1688)\n",
       "\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:64)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:63)\n",
       "\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.generateTemporaryPathCredentials(ProfiledManagedCatalog.scala:726)\n",
       "\tat com.databricks.unity.CredentialScopeSQLHelper$.checkPathOperations(CredentialScopeSQLHelper.scala:146)\n",
       "\tat com.databricks.unity.CredentialScopeSQLHelper$.register(CredentialScopeSQLHelper.scala:194)\n",
       "\tat com.databricks.unity.CredentialScopeSQLHelper$.registerCreateTableAccess(CredentialScopeSQLHelper.scala:1186)\n",
       "\tat com.databricks.sql.managedcatalog.CredentialScopeTableCredentialHandler.injectCredential(ResolveWithCredential.scala:516)\n",
       "\tat com.databricks.sql.managedcatalog.ResolveWithCredential.com$databricks$sql$managedcatalog$ResolveWithCredential$$maybeDecorateCatalogTable(ResolveWithCredential.scala:83)\n",
       "\tat com.databricks.sql.managedcatalog.ResolveWithCredential$$anonfun$apply$1.applyOrElse(ResolveWithCredential.scala:148)\n",
       "\tat com.databricks.sql.managedcatalog.ResolveWithCredential$$anonfun$apply$1.applyOrElse(ResolveWithCredential.scala:146)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:201)\n",
       "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:201)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:199)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:195)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDown(AnalysisHelper.scala:191)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDown$(AnalysisHelper.scala:190)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:42)\n",
       "\tat com.databricks.sql.managedcatalog.ResolveWithCredential.apply(ResolveWithCredential.scala:146)\n",
       "\tat com.databricks.sql.managedcatalog.ResolveWithCredential.apply(ResolveWithCredential.scala:69)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$16(RuleExecutor.scala:480)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RecoverableRuleExecutionHelper.processRule(RuleExecutor.scala:629)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RecoverableRuleExecutionHelper.processRule$(RuleExecutor.scala:613)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.processRule(RuleExecutor.scala:131)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$15(RuleExecutor.scala:480)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$14(RuleExecutor.scala:479)\n",
       "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
       "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
       "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$13(RuleExecutor.scala:475)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeBatch$1(RuleExecutor.scala:452)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$22(RuleExecutor.scala:585)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$22$adapted(RuleExecutor.scala:585)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:585)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:349)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeSameContext(Analyzer.scala:498)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:491)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:397)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:491)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:416)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:341)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)\n",
       "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:341)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:252)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:96)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:131)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:87)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:478)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:478)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:294)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:668)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:668)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1307)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:661)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:658)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:658)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:288)\n",
       "\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:287)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n",
       "\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n",
       "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:321)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:267)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:149)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1469)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1469)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1142)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1094)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1166)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:372)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:472)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:496)\n",
       "\tat scala.collection.immutable.List.map(List.scala:293)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:491)\n",
       "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:39)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$36(DriverLocal.scala:1320)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n",
       "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$30(DriverLocal.scala:1311)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:130)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:130)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1236)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1720)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:879)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:1046)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:1035)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:1081)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:81)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:81)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:1081)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:758)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:851)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:622)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:617)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:540)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:371)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
       "\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\n",
       "\t\tat com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:118)\n",
       "\t\tat com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:63)\n",
       "\t\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:251)\n",
       "\t\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7378)\n",
       "\t\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7364)\n",
       "\t\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.generateTemporaryPathCredentials(ManagedCatalogClientImpl.scala:6421)\n",
       "\t\tat com.databricks.sql.managedcatalog.ManagedCatalogCommon.generateTemporaryPathCredentials(ManagedCatalogCommon.scala:3238)\n",
       "\t\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$generateTemporaryPathCredentials$2(ProfiledManagedCatalog.scala:726)\n",
       "\t\tat org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:1688)\n",
       "\t\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:64)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:63)\n",
       "\t\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.generateTemporaryPathCredentials(ProfiledManagedCatalog.scala:726)\n",
       "\t\tat com.databricks.unity.CredentialScopeSQLHelper$.checkPathOperations(CredentialScopeSQLHelper.scala:146)\n",
       "\t\tat com.databricks.unity.CredentialScopeSQLHelper$.register(CredentialScopeSQLHelper.scala:194)\n",
       "\t\tat com.databricks.unity.CredentialScopeSQLHelper$.registerCreateTableAccess(CredentialScopeSQLHelper.scala:1186)\n",
       "\t\tat com.databricks.sql.managedcatalog.CredentialScopeTableCredentialHandler.injectCredential(ResolveWithCredential.scala:516)\n",
       "\t\tat com.databricks.sql.managedcatalog.ResolveWithCredential.com$databricks$sql$managedcatalog$ResolveWithCredential$$maybeDecorateCatalogTable(ResolveWithCredential.scala:83)\n",
       "\t\tat com.databricks.sql.managedcatalog.ResolveWithCredential$$anonfun$apply$1.applyOrElse(ResolveWithCredential.scala:148)\n",
       "\t\tat com.databricks.sql.managedcatalog.ResolveWithCredential$$anonfun$apply$1.applyOrElse(ResolveWithCredential.scala:146)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:201)\n",
       "\t\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:201)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:199)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:195)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:42)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDown(AnalysisHelper.scala:191)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDown$(AnalysisHelper.scala:190)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:42)\n",
       "\t\tat com.databricks.sql.managedcatalog.ResolveWithCredential.apply(ResolveWithCredential.scala:146)\n",
       "\t\tat com.databricks.sql.managedcatalog.ResolveWithCredential.apply(ResolveWithCredential.scala:69)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$16(RuleExecutor.scala:480)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RecoverableRuleExecutionHelper.processRule(RuleExecutor.scala:629)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RecoverableRuleExecutionHelper.processRule$(RuleExecutor.scala:613)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.processRule(RuleExecutor.scala:131)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$15(RuleExecutor.scala:480)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$14(RuleExecutor.scala:479)\n",
       "\t\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
       "\t\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
       "\t\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$13(RuleExecutor.scala:475)\n",
       "\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeBatch$1(RuleExecutor.scala:452)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$22(RuleExecutor.scala:585)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$22$adapted(RuleExecutor.scala:585)\n",
       "\t\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:585)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:349)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeSameContext(Analyzer.scala:498)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:491)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:397)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:491)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:416)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:341)\n",
       "\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)\n",
       "\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:341)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:252)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:96)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:131)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:87)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:478)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:478)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:294)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:668)\n",
       "\t\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:668)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1307)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:661)\n",
       "\t\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:658)\n",
       "\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:658)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:288)\n",
       "\t\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:287)\n",
       "\t\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n",
       "\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n",
       "\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n",
       "\t\t... 71 more\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "UnityCatalogServiceException: [RequestId=1391a6f6-5844-4086-aa36-c4cad6d95014 ErrorClass=INVALID_PARAMETER_VALUE.INVALID_PARAMETER_VALUE] Missing cloud file system scheme"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": null,
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": null,
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "com.databricks.sql.managedcatalog.UnityCatalogServiceException: [RequestId=1391a6f6-5844-4086-aa36-c4cad6d95014 ErrorClass=INVALID_PARAMETER_VALUE.INVALID_PARAMETER_VALUE] Missing cloud file system scheme\n\tat com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:118)\n\tat com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:63)\n\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:251)\n\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7378)\n\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7364)\n\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.generateTemporaryPathCredentials(ManagedCatalogClientImpl.scala:6421)\n\tat com.databricks.sql.managedcatalog.ManagedCatalogCommon.generateTemporaryPathCredentials(ManagedCatalogCommon.scala:3238)\n\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$generateTemporaryPathCredentials$2(ProfiledManagedCatalog.scala:726)\n\tat org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:1688)\n\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:64)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:63)\n\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.generateTemporaryPathCredentials(ProfiledManagedCatalog.scala:726)\n\tat com.databricks.unity.CredentialScopeSQLHelper$.checkPathOperations(CredentialScopeSQLHelper.scala:146)\n\tat com.databricks.unity.CredentialScopeSQLHelper$.register(CredentialScopeSQLHelper.scala:194)\n\tat com.databricks.unity.CredentialScopeSQLHelper$.registerCreateTableAccess(CredentialScopeSQLHelper.scala:1186)\n\tat com.databricks.sql.managedcatalog.CredentialScopeTableCredentialHandler.injectCredential(ResolveWithCredential.scala:516)\n\tat com.databricks.sql.managedcatalog.ResolveWithCredential.com$databricks$sql$managedcatalog$ResolveWithCredential$$maybeDecorateCatalogTable(ResolveWithCredential.scala:83)\n\tat com.databricks.sql.managedcatalog.ResolveWithCredential$$anonfun$apply$1.applyOrElse(ResolveWithCredential.scala:148)\n\tat com.databricks.sql.managedcatalog.ResolveWithCredential$$anonfun$apply$1.applyOrElse(ResolveWithCredential.scala:146)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:199)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:195)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDown(AnalysisHelper.scala:191)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDown$(AnalysisHelper.scala:190)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:42)\n\tat com.databricks.sql.managedcatalog.ResolveWithCredential.apply(ResolveWithCredential.scala:146)\n\tat com.databricks.sql.managedcatalog.ResolveWithCredential.apply(ResolveWithCredential.scala:69)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$16(RuleExecutor.scala:480)\n\tat org.apache.spark.sql.catalyst.rules.RecoverableRuleExecutionHelper.processRule(RuleExecutor.scala:629)\n\tat org.apache.spark.sql.catalyst.rules.RecoverableRuleExecutionHelper.processRule$(RuleExecutor.scala:613)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.processRule(RuleExecutor.scala:131)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$15(RuleExecutor.scala:480)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$14(RuleExecutor.scala:479)\n\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$13(RuleExecutor.scala:475)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeBatch$1(RuleExecutor.scala:452)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$22(RuleExecutor.scala:585)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$22$adapted(RuleExecutor.scala:585)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:585)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:349)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeSameContext(Analyzer.scala:498)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:491)\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:397)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:491)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:416)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:341)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:341)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:252)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:96)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:131)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:87)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:478)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:478)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:294)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:668)\n\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:668)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1307)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:661)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:658)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:658)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:288)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:287)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:321)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:267)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:149)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1469)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1469)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1142)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1094)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1166)\n\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:372)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:472)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:496)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:491)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:39)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$36(DriverLocal.scala:1320)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$30(DriverLocal.scala:1311)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:130)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:130)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1236)\n\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1720)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:879)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:1046)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:1035)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:1081)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:81)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:81)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:1081)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:758)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:851)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:622)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:617)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:540)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:371)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\n\t\tat com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:118)\n\t\tat com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:63)\n\t\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:251)\n\t\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7378)\n\t\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7364)\n\t\tat com.databricks.managedcatalog.ManagedCatalogClientImpl.generateTemporaryPathCredentials(ManagedCatalogClientImpl.scala:6421)\n\t\tat com.databricks.sql.managedcatalog.ManagedCatalogCommon.generateTemporaryPathCredentials(ManagedCatalogCommon.scala:3238)\n\t\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$generateTemporaryPathCredentials$2(ProfiledManagedCatalog.scala:726)\n\t\tat org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:1688)\n\t\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:64)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:63)\n\t\tat com.databricks.sql.managedcatalog.ProfiledManagedCatalog.generateTemporaryPathCredentials(ProfiledManagedCatalog.scala:726)\n\t\tat com.databricks.unity.CredentialScopeSQLHelper$.checkPathOperations(CredentialScopeSQLHelper.scala:146)\n\t\tat com.databricks.unity.CredentialScopeSQLHelper$.register(CredentialScopeSQLHelper.scala:194)\n\t\tat com.databricks.unity.CredentialScopeSQLHelper$.registerCreateTableAccess(CredentialScopeSQLHelper.scala:1186)\n\t\tat com.databricks.sql.managedcatalog.CredentialScopeTableCredentialHandler.injectCredential(ResolveWithCredential.scala:516)\n\t\tat com.databricks.sql.managedcatalog.ResolveWithCredential.com$databricks$sql$managedcatalog$ResolveWithCredential$$maybeDecorateCatalogTable(ResolveWithCredential.scala:83)\n\t\tat com.databricks.sql.managedcatalog.ResolveWithCredential$$anonfun$apply$1.applyOrElse(ResolveWithCredential.scala:148)\n\t\tat com.databricks.sql.managedcatalog.ResolveWithCredential$$anonfun$apply$1.applyOrElse(ResolveWithCredential.scala:146)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:201)\n\t\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:201)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:199)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:195)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:42)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDown(AnalysisHelper.scala:191)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDown$(AnalysisHelper.scala:190)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:42)\n\t\tat com.databricks.sql.managedcatalog.ResolveWithCredential.apply(ResolveWithCredential.scala:146)\n\t\tat com.databricks.sql.managedcatalog.ResolveWithCredential.apply(ResolveWithCredential.scala:69)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$16(RuleExecutor.scala:480)\n\t\tat org.apache.spark.sql.catalyst.rules.RecoverableRuleExecutionHelper.processRule(RuleExecutor.scala:629)\n\t\tat org.apache.spark.sql.catalyst.rules.RecoverableRuleExecutionHelper.processRule$(RuleExecutor.scala:613)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.processRule(RuleExecutor.scala:131)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$15(RuleExecutor.scala:480)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$14(RuleExecutor.scala:479)\n\t\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n\t\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n\t\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$13(RuleExecutor.scala:475)\n\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeBatch$1(RuleExecutor.scala:452)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$22(RuleExecutor.scala:585)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$22$adapted(RuleExecutor.scala:585)\n\t\tat scala.collection.immutable.List.foreach(List.scala:431)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:585)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:349)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeSameContext(Analyzer.scala:498)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:491)\n\t\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:397)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:491)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:416)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:341)\n\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:341)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:252)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:96)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:131)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:87)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:478)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:478)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:294)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:668)\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:668)\n\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1307)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:661)\n\t\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:658)\n\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n\t\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:658)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:288)\n\t\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:287)\n\t\tat scala.util.Try$.apply(Try.scala:213)\n\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n\t\t... 71 more\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- Cria uma tabela a partir do arquivo JSON com comando Using \n",
    "CREATE TABLE infinitybd.default.iot_devicesj\n",
    "USING json\n",
    "LOCATION 'dbfs:/Volumes/infinitybd/default/mnt/iot/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d0fc4d5-f4e1-4585-a531-9f3bddea74bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `default`.`iot_devices` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
       "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 2 pos 21;\n",
       "'Aggregate [unresolvedalias(count(1))]\n",
       "+- 'UnresolvedRelation [default, iot_devices], [], false\n",
       "\n",
       "\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:345)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:307)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:303)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:302)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:302)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:302)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:307)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:278)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:416)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:263)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:250)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:250)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:416)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:254)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:254)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:96)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:131)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:87)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:478)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:478)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:294)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:668)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:668)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1307)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:661)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:658)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:658)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:288)\n",
       "\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:287)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n",
       "\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n",
       "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:321)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:267)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:149)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1469)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1469)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1142)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1094)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1166)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:372)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:472)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:496)\n",
       "\tat scala.collection.immutable.List.map(List.scala:293)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:491)\n",
       "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:39)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$36(DriverLocal.scala:1320)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n",
       "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$30(DriverLocal.scala:1311)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:130)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:130)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1236)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1720)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:879)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:1046)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:1035)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:1081)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:81)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:81)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:1081)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:758)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:851)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:622)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:617)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:540)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:371)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
       "\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:345)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:307)\n",
       "\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:303)\n",
       "\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:302)\n",
       "\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:302)\n",
       "\t\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\t\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\t\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\t\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\t\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\t\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:302)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:307)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:278)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:416)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:263)\n",
       "\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:250)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:250)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:416)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:254)\n",
       "\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:254)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:96)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:131)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:87)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:478)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:478)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:294)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:668)\n",
       "\t\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:668)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1307)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:661)\n",
       "\t\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:658)\n",
       "\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:658)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:288)\n",
       "\t\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:287)\n",
       "\t\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n",
       "\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n",
       "\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n",
       "\t\t... 71 more\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `default`.`iot_devices` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "TABLE_OR_VIEW_NOT_FOUND",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "42P01",
        "stackTrace": null,
        "startIndex": 69,
        "stopIndex": 87
       },
       "stackFrames": [
        "org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `default`.`iot_devices` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 2 pos 21;\n'Aggregate [unresolvedalias(count(1))]\n+- 'UnresolvedRelation [default, iot_devices], [], false\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:345)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:307)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:303)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:302)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:302)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:302)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:307)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:278)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:416)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:263)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:250)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:250)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:416)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:254)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:254)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:96)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:131)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:87)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:478)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:478)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:294)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:668)\n\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:668)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1307)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:661)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:658)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:658)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:288)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:287)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:321)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:267)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:149)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1469)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1469)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1142)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1094)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1166)\n\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:372)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:472)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:496)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:491)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:39)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$36(DriverLocal.scala:1320)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$30(DriverLocal.scala:1311)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:130)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:130)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1236)\n\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1720)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:879)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:1046)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:1035)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:1081)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:81)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:81)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:1081)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:758)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:851)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:622)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:617)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:540)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:371)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\n\t\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:345)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:307)\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:303)\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:302)\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:302)\n\t\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\t\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\t\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\t\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\t\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\t\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:302)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:307)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:278)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:416)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:263)\n\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:250)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:250)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:416)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:254)\n\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:254)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:96)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:131)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:87)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:478)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:478)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:294)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:668)\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:668)\n\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1307)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:661)\n\t\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:658)\n\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)\n\t\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:658)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:288)\n\t\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:287)\n\t\tat scala.util.Try$.apply(Try.scala:213)\n\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n\t\t... 71 more\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- Conta o número de registros na tabela criada\n",
    "SELECT COUNT(*) FROM default.iot_devices;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71ebe3e4-4fff-4bcc-bac9-75507448e45f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a442490-9d76-49f8-9148-5aa44b8b3e86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Criando tabela Delta a partir de arquivo com CREATE TABLE AS (CTAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4503c7fe-1902-475f-b962-25083906a54c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- Comandos CTA  inferem os tipos de dados altomaticamente\n",
    "-- Desafio: Criar tabela iot_devices_dt \n",
    "CREATE TABLE default.iot_devices_dt\n",
    "AS\n",
    "SELECT * FROM json.`/Volumes/infinitybd/default/mnt/iot/*.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7809a9bb-3730-4a1b-b2d1-b465621a2e99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>battery_level</th><th>c02_level</th><th>cca2</th><th>cca3</th><th>cn</th><th>device_id</th><th>device_name</th><th>humidity</th><th>ip</th><th>latitude</th><th>lcd</th><th>longitude</th><th>scale</th><th>temp</th><th>timestamp</th></tr></thead><tbody><tr><td>8</td><td>868</td><td>US</td><td>USA</td><td>United States</td><td>1</td><td>meter-gauge-1xbYRYcj</td><td>51</td><td>68.161.225.1</td><td>38.0</td><td>green</td><td>-97.0</td><td>Celsius</td><td>34</td><td>1458444054093</td></tr><tr><td>7</td><td>1473</td><td>NO</td><td>NOR</td><td>Norway</td><td>2</td><td>sensor-pad-2n2Pea</td><td>70</td><td>213.161.254.1</td><td>62.47</td><td>red</td><td>6.15</td><td>Celsius</td><td>11</td><td>1458444054119</td></tr><tr><td>2</td><td>1556</td><td>IT</td><td>ITA</td><td>Italy</td><td>3</td><td>device-mac-36TWSKiT</td><td>44</td><td>88.36.5.1</td><td>42.83</td><td>red</td><td>12.83</td><td>Celsius</td><td>19</td><td>1458444054120</td></tr><tr><td>6</td><td>1080</td><td>US</td><td>USA</td><td>United States</td><td>4</td><td>sensor-pad-4mzWkz</td><td>32</td><td>66.39.173.154</td><td>44.06</td><td>yellow</td><td>-121.32</td><td>Celsius</td><td>28</td><td>1458444054121</td></tr><tr><td>4</td><td>931</td><td>PH</td><td>PHL</td><td>Philippines</td><td>5</td><td>therm-stick-5gimpUrBB</td><td>62</td><td>203.82.41.9</td><td>14.58</td><td>green</td><td>120.97</td><td>Celsius</td><td>25</td><td>1458444054122</td></tr><tr><td>3</td><td>1210</td><td>US</td><td>USA</td><td>United States</td><td>6</td><td>sensor-pad-6al7RTAobR</td><td>51</td><td>204.116.105.67</td><td>35.93</td><td>yellow</td><td>-85.46</td><td>Celsius</td><td>27</td><td>1458444054122</td></tr><tr><td>3</td><td>1129</td><td>CN</td><td>CHN</td><td>China</td><td>7</td><td>meter-gauge-7GeDoanM</td><td>26</td><td>220.173.179.1</td><td>22.82</td><td>yellow</td><td>108.32</td><td>Celsius</td><td>18</td><td>1458444054123</td></tr><tr><td>0</td><td>1536</td><td>JP</td><td>JPN</td><td>Japan</td><td>8</td><td>sensor-pad-8xUD6pzsQI</td><td>35</td><td>210.173.177.1</td><td>35.69</td><td>red</td><td>139.69</td><td>Celsius</td><td>27</td><td>1458444054123</td></tr><tr><td>3</td><td>807</td><td>JP</td><td>JPN</td><td>Japan</td><td>9</td><td>device-mac-9GcjZ2pw</td><td>85</td><td>118.23.68.227</td><td>35.69</td><td>green</td><td>139.69</td><td>Celsius</td><td>13</td><td>1458444054124</td></tr><tr><td>7</td><td>1470</td><td>US</td><td>USA</td><td>United States</td><td>10</td><td>sensor-pad-10BsywSYUF</td><td>56</td><td>208.109.163.218</td><td>33.61</td><td>red</td><td>-111.89</td><td>Celsius</td><td>26</td><td>1458444054125</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         8,
         868,
         "US",
         "USA",
         "United States",
         1,
         "meter-gauge-1xbYRYcj",
         51,
         "68.161.225.1",
         38.0,
         "green",
         -97.0,
         "Celsius",
         34,
         1458444054093
        ],
        [
         7,
         1473,
         "NO",
         "NOR",
         "Norway",
         2,
         "sensor-pad-2n2Pea",
         70,
         "213.161.254.1",
         62.47,
         "red",
         6.15,
         "Celsius",
         11,
         1458444054119
        ],
        [
         2,
         1556,
         "IT",
         "ITA",
         "Italy",
         3,
         "device-mac-36TWSKiT",
         44,
         "88.36.5.1",
         42.83,
         "red",
         12.83,
         "Celsius",
         19,
         1458444054120
        ],
        [
         6,
         1080,
         "US",
         "USA",
         "United States",
         4,
         "sensor-pad-4mzWkz",
         32,
         "66.39.173.154",
         44.06,
         "yellow",
         -121.32,
         "Celsius",
         28,
         1458444054121
        ],
        [
         4,
         931,
         "PH",
         "PHL",
         "Philippines",
         5,
         "therm-stick-5gimpUrBB",
         62,
         "203.82.41.9",
         14.58,
         "green",
         120.97,
         "Celsius",
         25,
         1458444054122
        ],
        [
         3,
         1210,
         "US",
         "USA",
         "United States",
         6,
         "sensor-pad-6al7RTAobR",
         51,
         "204.116.105.67",
         35.93,
         "yellow",
         -85.46,
         "Celsius",
         27,
         1458444054122
        ],
        [
         3,
         1129,
         "CN",
         "CHN",
         "China",
         7,
         "meter-gauge-7GeDoanM",
         26,
         "220.173.179.1",
         22.82,
         "yellow",
         108.32,
         "Celsius",
         18,
         1458444054123
        ],
        [
         0,
         1536,
         "JP",
         "JPN",
         "Japan",
         8,
         "sensor-pad-8xUD6pzsQI",
         35,
         "210.173.177.1",
         35.69,
         "red",
         139.69,
         "Celsius",
         27,
         1458444054123
        ],
        [
         3,
         807,
         "JP",
         "JPN",
         "Japan",
         9,
         "device-mac-9GcjZ2pw",
         85,
         "118.23.68.227",
         35.69,
         "green",
         139.69,
         "Celsius",
         13,
         1458444054124
        ],
        [
         7,
         1470,
         "US",
         "USA",
         "United States",
         10,
         "sensor-pad-10BsywSYUF",
         56,
         "208.109.163.218",
         33.61,
         "red",
         -111.89,
         "Celsius",
         26,
         1458444054125
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "battery_level",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "c02_level",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cca2",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cca3",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cn",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "device_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "device_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "humidity",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ip",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "latitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "lcd",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "longitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "scale",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "temp",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECT * FROM default.iot_devices_dt limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55b5f008-bb06-4338-98a9-0784b8472cc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>198164</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         198164
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "count(1)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECT COUNT(*) FROM default.iot_devices_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ad6870e-18be-4c86-bd0f-4f32248c08de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>battery_level</td><td>bigint</td><td>null</td></tr><tr><td>c02_level</td><td>bigint</td><td>null</td></tr><tr><td>cca2</td><td>string</td><td>null</td></tr><tr><td>cca3</td><td>string</td><td>null</td></tr><tr><td>cn</td><td>string</td><td>null</td></tr><tr><td>device_id</td><td>bigint</td><td>null</td></tr><tr><td>device_name</td><td>string</td><td>null</td></tr><tr><td>humidity</td><td>bigint</td><td>null</td></tr><tr><td>ip</td><td>string</td><td>null</td></tr><tr><td>latitude</td><td>double</td><td>null</td></tr><tr><td>lcd</td><td>string</td><td>null</td></tr><tr><td>longitude</td><td>double</td><td>null</td></tr><tr><td>scale</td><td>string</td><td>null</td></tr><tr><td>temp</td><td>bigint</td><td>null</td></tr><tr><td>timestamp</td><td>bigint</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Delta Statistics Columns</td><td></td><td></td></tr><tr><td>Column Names</td><td>device_name, device_id, ip, timestamp, latitude, lcd, scale, cn, longitude, cca3, humidity, temp, cca2, c02_level, battery_level</td><td></td></tr><tr><td>Column Selection Method</td><td>first-32</td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Catalog</td><td>infinitybd</td><td></td></tr><tr><td>Database</td><td>default</td><td></td></tr><tr><td>Table</td><td>iot_devices_dt</td><td></td></tr><tr><td>Created Time</td><td>Thu Aug 14 17:16:41 UTC 2025</td><td></td></tr><tr><td>Last Access</td><td>UNKNOWN</td><td></td></tr><tr><td>Created By</td><td>Spark </td><td></td></tr><tr><td>Type</td><td>MANAGED</td><td></td></tr><tr><td>Location</td><td>abfss://unity-catalog-storage@dbstoragehwpfx2cio4tbi.dfs.core.windows.net/996433462057401/__unitystorage/catalogs/eda9cffd-a651-489e-8077-718cedfef2a9/tables/9d8799ec-45bb-4086-a4f7-6d6895ce203c</td><td></td></tr><tr><td>Provider</td><td>delta</td><td></td></tr><tr><td>Owner</td><td>infinitybigdata@gmail.com</td><td></td></tr><tr><td>Is_managed_location</td><td>true</td><td></td></tr><tr><td>Predictive Optimization</td><td>ENABLE (inherited from METASTORE metastore_azure_eastus)</td><td></td></tr><tr><td>Table Properties</td><td>[delta.enableDeletionVectors=true,delta.feature.appendOnly=supported,delta.feature.deletionVectors=supported,delta.feature.invariants=supported,delta.minReaderVersion=3,delta.minWriterVersion=7]</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "battery_level",
         "bigint",
         null
        ],
        [
         "c02_level",
         "bigint",
         null
        ],
        [
         "cca2",
         "string",
         null
        ],
        [
         "cca3",
         "string",
         null
        ],
        [
         "cn",
         "string",
         null
        ],
        [
         "device_id",
         "bigint",
         null
        ],
        [
         "device_name",
         "string",
         null
        ],
        [
         "humidity",
         "bigint",
         null
        ],
        [
         "ip",
         "string",
         null
        ],
        [
         "latitude",
         "double",
         null
        ],
        [
         "lcd",
         "string",
         null
        ],
        [
         "longitude",
         "double",
         null
        ],
        [
         "scale",
         "string",
         null
        ],
        [
         "temp",
         "bigint",
         null
        ],
        [
         "timestamp",
         "bigint",
         null
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Delta Statistics Columns",
         "",
         ""
        ],
        [
         "Column Names",
         "device_name, device_id, ip, timestamp, latitude, lcd, scale, cn, longitude, cca3, humidity, temp, cca2, c02_level, battery_level",
         ""
        ],
        [
         "Column Selection Method",
         "first-32",
         ""
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Detailed Table Information",
         "",
         ""
        ],
        [
         "Catalog",
         "infinitybd",
         ""
        ],
        [
         "Database",
         "default",
         ""
        ],
        [
         "Table",
         "iot_devices_dt",
         ""
        ],
        [
         "Created Time",
         "Thu Aug 14 17:16:41 UTC 2025",
         ""
        ],
        [
         "Last Access",
         "UNKNOWN",
         ""
        ],
        [
         "Created By",
         "Spark ",
         ""
        ],
        [
         "Type",
         "MANAGED",
         ""
        ],
        [
         "Location",
         "abfss://unity-catalog-storage@dbstoragehwpfx2cio4tbi.dfs.core.windows.net/996433462057401/__unitystorage/catalogs/eda9cffd-a651-489e-8077-718cedfef2a9/tables/9d8799ec-45bb-4086-a4f7-6d6895ce203c",
         ""
        ],
        [
         "Provider",
         "delta",
         ""
        ],
        [
         "Owner",
         "infinitybigdata@gmail.com",
         ""
        ],
        [
         "Is_managed_location",
         "true",
         ""
        ],
        [
         "Predictive Optimization",
         "ENABLE (inherited from METASTORE metastore_azure_eastus)",
         ""
        ],
        [
         "Table Properties",
         "[delta.enableDeletionVectors=true,delta.feature.appendOnly=supported,delta.feature.deletionVectors=supported,delta.feature.invariants=supported,delta.minReaderVersion=3,delta.minWriterVersion=7]",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\":\"name of the column\"}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"data type of the column\"}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"comment of the column\"}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DESCRIBE EXTENDED default.iot_devices_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beb8bffc-4b76-4ff7-a4a3-564cca4f0b44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Final se prescisar apagar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edb9c1fb-de17-4812-bc93-43e622f93628",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DROP TABLE IF EXISTS default.iot_devices;\n",
    "DROP TABLE IF EXISTS default.iot_devices_dt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe644878-87e7-4922-8670-85f0703e4daa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- Remove todo o conteúdo e o volume\n",
    "DROP VOLUME IF EXISTS infinitybd.default.teste;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 586349299729661,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03.Unity Catalog",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}